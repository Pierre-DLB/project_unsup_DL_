{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhFZbGtMwAWs"
      },
      "source": [
        "In this Google Colab cell, we will be downloading two distinct datasets for a text style transfer task. The goal is to develop a model capable of translating text between the writing styles of William Shakespeare and a more modern English author. For this purpose, we have chosen two datasets:\n",
        "\n",
        "    Shakespeare's Complete Works: This dataset includes the entire collection of plays and poems written by William Shakespeare. Shakespeare's works represent early modern English with a rich and unique style, making them ideal for studying stylistic differences compared to contemporary English.\n",
        "\n",
        "    \"Pride and Prejudice\" by Jane Austen: As a representative of more modern English, we've chosen Jane Austen's famous novel \"Pride and Prejudice\". While not contemporary in the current sense, Austen's language is more aligned with modern English than Shakespeare's, yet it maintains a level of formality and complexity in its style. This contrast will provide a challenging yet insightful basis for the style transfer model.\n",
        "\n",
        "By downloading and utilizing these two datasets, we aim to explore the nuances of linguistic style transfer, particularly focusing on the transformation of syntactic and stylistic elements between the two distinct forms of English.\n",
        "\n",
        "The following script will download both datasets from Project Gutenberg, which is a reliable source for public domain texts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fw7zP0hto3b",
        "outputId": "9477fd69-3881-4a27-d628-2fc2d25e5900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded Shakespeare's Complete Works\n",
            "Downloaded 'Pride and Prejudice' by Jane Austen\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Download Shakespeare's Complete Works\n",
        "shakespeare_url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
        "response = requests.get(shakespeare_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    shakespeare_text = response.text\n",
        "    with open('shakespeare_complete_works.txt', 'w', encoding='utf-8') as file:\n",
        "        file.write(shakespeare_text)\n",
        "    print(\"Downloaded Shakespeare's Complete Works\")\n",
        "else:\n",
        "    print(\"Failed to download Shakespeare's Complete Works\")\n",
        "\n",
        "# Download \"Pride and Prejudice\" by Jane Austen\n",
        "pride_prejudice_url = 'https://www.gutenberg.org/files/1342/1342-0.txt'\n",
        "response = requests.get(pride_prejudice_url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    pride_prejudice_text = response.text\n",
        "    with open('pride_and_prejudice.txt', 'w', encoding='utf-8') as file:\n",
        "        file.write(pride_prejudice_text)\n",
        "    print(\"Downloaded 'Pride and Prejudice' by Jane Austen\")\n",
        "else:\n",
        "    print(\"Failed to download 'Pride and Prejudice'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz46eOO9weVr"
      },
      "source": [
        "To achieve style transfer between Shakespearean English and more modern English using the datasets provided, you can follow these steps:\n",
        "\n",
        "- **Data Preprocessing**:\n",
        "  - Tokenize and clean both datasets. This includes removing special characters, headers, and footers from the Project Gutenberg files.\n",
        "  - Break down the text into smaller chunks (e.g., sentences or paragraphs) for easier processing.\n",
        "\n",
        "- **Exploratory Data Analysis (EDA)**:\n",
        "  - Analyze the unique characteristics of each style, such as common words, sentence length, and syntactic structures.\n",
        "  - Use visualization tools to highlight these differences.\n",
        "\n",
        "- **Creating a Pseudo Parallel Corpus**\n",
        "  - Explain why we need that\n",
        "  - Propose unsupervised methods to find semantically similar sentences across the two datasets.\n",
        "  - Check if they do indeed match\n",
        "\n",
        "- **Model Selection and Implementation**:\n",
        "  - **Choose a suitable NLP model for style transfer.** Discuss this choice\n",
        "  - Fine-tune the model on the style transfer task using the prepared datasets.\n",
        "\n",
        "Further, if time allows:\n",
        "- **Evaluation**:\n",
        "  - Develop a set of metrics to evaluate the effectiveness of the style transfer, such as BLEU score, perplexity, and a qualitative assessment by human readers.\n",
        "  - Compare the output of the model with the target style to assess how well it has captured the stylistic elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TTItz6c3wZuC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (4.35.0)\n",
            "Requirement already satisfied: tqdm in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (2.1.0)\n",
            "Collecting torchvision (from sentence-transformers)\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/02/b6/a540edc7ebcd510d42611e4344bbaa9c73e0c262750652e276866b43e33e/torchvision-0.16.1-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torchvision-0.16.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (1.25.2)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/70/d0/50ace22129f79830e3cf682d0a2bd4843ef91573299d43112d52790163a8/scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/de/0d/4fa68303568c70fd56fbf40668b6c6807cfee4cad975f07d80bdd26d013e/scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
            "  Downloading scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sentence-transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
            "Requirement already satisfied: requests in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
            "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
            "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting torch>=1.6.0 (from sentence-transformers)\n",
            "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/25/5d/22b4d5d2183e03f197a5e6b2721bb8f7a3e92b4947b16b70316c1e3771f3/torch-2.1.1-cp310-none-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading torch-2.1.1-cp310-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/pierr/Library/Caches/pypoetry/virtualenvs/test-mistral-7b-K_6rIumS-py3.10/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Downloading scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-macosx_12_0_arm64.whl (29.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.1-cp310-cp310-macosx_11_0_arm64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hDownloading torch-2.1.1-cp310-none-macosx_11_0_arm64.whl (59.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=7e86749096f22cd6744c6a1a2a8963e0948608541b21f6c7b25cc3d17df260b7\n",
            "  Stored in directory: /Users/pierr/Library/Caches/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, threadpoolctl, scipy, torch, scikit-learn, torchvision, sentence-transformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0\n",
            "    Uninstalling torch-2.1.0:\n",
            "      Successfully uninstalled torch-2.1.0\n",
            "Successfully installed scikit-learn-1.3.2 scipy-1.11.4 sentence-transformers-2.2.2 sentencepiece-0.1.99 threadpoolctl-3.2.0 torch-2.1.1 torchvision-0.16.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading .gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 2.42MB/s]\n",
            "Downloading 1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 931kB/s]\n",
            "Downloading README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 26.9MB/s]\n",
            "Downloading config.json: 100%|██████████| 612/612 [00:00<00:00, 2.86MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 553kB/s]\n",
            "Downloading data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 10.2MB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:18<00:00, 4.92MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 163kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 385kB/s]\n",
            "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.62MB/s]\n",
            "Downloading tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.16MB/s]\n",
            "Downloading train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 18.9MB/s]\n",
            "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 30.6MB/s]\n",
            "Downloading modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.16MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 6.76569268e-02  6.34958595e-02  4.87131663e-02  7.93049484e-02\n",
            "   3.74480151e-02  2.65273103e-03  3.93748954e-02 -7.09838420e-03\n",
            "   5.93614578e-02  3.15370075e-02  6.00980110e-02 -5.29051572e-02\n",
            "   4.06067595e-02 -2.59308219e-02  2.98427958e-02  1.12688739e-03\n",
            "   7.35148787e-02 -5.03818542e-02 -1.22386679e-01  2.37027854e-02\n",
            "   2.97265742e-02  4.24768254e-02  2.56337989e-02  1.99515815e-03\n",
            "  -5.69191836e-02 -2.71599442e-02 -3.29035930e-02  6.60248697e-02\n",
            "   1.19007140e-01 -4.58791628e-02 -7.26214647e-02 -3.25841382e-02\n",
            "   5.23413569e-02  4.50552553e-02  8.25307053e-03  3.67024280e-02\n",
            "  -1.39414705e-02  6.53919429e-02 -2.64272261e-02  2.06371697e-04\n",
            "  -1.36643583e-02 -3.62810344e-02 -1.95043348e-02 -2.89738476e-02\n",
            "   3.94270569e-02 -8.84091258e-02  2.62428215e-03  1.36713954e-02\n",
            "   4.83062603e-02 -3.11565734e-02 -1.17329232e-01 -5.11690266e-02\n",
            "  -8.85287672e-02 -2.18963381e-02  1.42985675e-02  4.44168337e-02\n",
            "  -1.34815322e-02  7.43392855e-02  2.66382322e-02 -1.98762473e-02\n",
            "   1.79191213e-02 -1.06052132e-02 -9.04263183e-02  2.13269182e-02\n",
            "   1.41204879e-01 -6.47168653e-03 -1.40377565e-03 -1.53609570e-02\n",
            "  -8.73572007e-02  7.22173899e-02  2.01403089e-02  4.25587408e-02\n",
            "  -3.49013470e-02  3.19604704e-04 -8.02970678e-02 -3.27472314e-02\n",
            "   2.85268351e-02 -5.13657480e-02  1.09389201e-01  8.19327235e-02\n",
            "  -9.84040126e-02 -9.34095532e-02 -1.51291462e-02  4.51248139e-02\n",
            "   4.94172238e-02 -2.51868088e-02  1.57077741e-02 -1.29290670e-01\n",
            "   5.31887589e-03  4.02342714e-03 -2.34571677e-02 -6.72983080e-02\n",
            "   2.92280465e-02 -2.60845292e-02  1.30624818e-02 -3.11663002e-02\n",
            "  -4.82714027e-02 -5.58859892e-02 -3.87505852e-02  1.20010853e-01\n",
            "  -1.03924265e-02  4.89704609e-02  5.53537235e-02  4.49359156e-02\n",
            "  -4.00967849e-03 -1.02959722e-01 -2.92968620e-02 -5.83401695e-02\n",
            "   2.70472653e-02 -2.20168810e-02 -7.22241178e-02 -4.13869321e-02\n",
            "  -1.93298571e-02  2.73326226e-03  2.76980747e-04 -9.67589170e-02\n",
            "  -1.00574695e-01 -1.41922869e-02 -8.07891563e-02  4.53924984e-02\n",
            "   2.45041270e-02  5.97613864e-02 -7.38185495e-02  1.19842980e-02\n",
            "  -6.63403943e-02 -7.69044757e-02  3.85157615e-02 -5.59362146e-33\n",
            "   2.80013606e-02 -5.60784712e-02 -4.86601815e-02  2.15570591e-02\n",
            "   6.01980761e-02 -4.81403023e-02 -3.50246951e-02  1.93314087e-02\n",
            "  -1.75151546e-02 -3.89210358e-02 -3.81064182e-03 -1.70287751e-02\n",
            "   2.82099638e-02  1.28290290e-02  4.71601449e-02  6.21029772e-02\n",
            "  -6.43588752e-02  1.29285574e-01 -1.31231323e-02  5.23069985e-02\n",
            "  -3.73681076e-02  2.89094262e-02 -1.68981142e-02 -2.37329751e-02\n",
            "  -3.33492681e-02 -5.16762659e-02  1.55356461e-02  2.08803285e-02\n",
            "  -1.25372456e-02  4.59579304e-02  3.72720435e-02  2.80566476e-02\n",
            "  -5.90004623e-02 -1.16988095e-02  4.92182821e-02  4.70328555e-02\n",
            "   7.35487193e-02 -3.70529443e-02  3.98463756e-03  1.06412042e-02\n",
            "  -1.61542950e-04 -5.27166687e-02  2.75928341e-02 -3.92921343e-02\n",
            "   8.44717249e-02  4.86860797e-02 -4.85872338e-03  1.79948900e-02\n",
            "  -4.28569727e-02  1.23376083e-02  6.39961194e-03  4.04823609e-02\n",
            "   1.48887420e-02 -1.53941400e-02  7.62947500e-02  2.37043723e-02\n",
            "   4.45237570e-02  5.08195199e-02 -2.31256452e-03 -1.88737176e-02\n",
            "  -1.23335831e-02  4.66002822e-02 -5.63437454e-02  6.29926622e-02\n",
            "  -3.15534659e-02  3.24912407e-02  2.34672837e-02 -6.55438155e-02\n",
            "   2.01708432e-02  2.57081911e-02 -1.23868166e-02 -8.36502109e-03\n",
            "  -6.64378032e-02  9.43073109e-02 -3.57093103e-02 -3.42483260e-02\n",
            "  -6.66356971e-03 -8.01534485e-03 -3.09712440e-02  4.33012508e-02\n",
            "  -8.21399316e-03 -1.50795057e-01  3.07691824e-02  4.00719047e-02\n",
            "  -3.79293673e-02  1.93209760e-03  4.00530547e-02 -8.77075121e-02\n",
            "  -3.68491150e-02  8.57951678e-03 -3.19251195e-02 -1.25257680e-02\n",
            "   7.35540166e-02  1.34737056e-03  2.05918867e-02  2.71097870e-33\n",
            "  -5.18577546e-02  5.78360260e-02 -9.18985307e-02  3.94421592e-02\n",
            "   1.05576545e-01 -1.96912698e-02  6.18403107e-02 -7.63465539e-02\n",
            "   2.40880754e-02  9.40048546e-02 -1.16535477e-01  3.71197686e-02\n",
            "   5.22425622e-02 -3.95858148e-03  5.72214313e-02  5.32853231e-03\n",
            "   1.24016851e-01  1.39022451e-02 -1.10249696e-02  3.56053263e-02\n",
            "  -3.30755524e-02  8.16573948e-02 -1.52004026e-02  6.05585016e-02\n",
            "  -6.01397082e-02  3.26102711e-02 -3.48296687e-02 -1.69882756e-02\n",
            "  -9.74907354e-02 -2.71484703e-02  1.74713659e-03 -7.68981501e-02\n",
            "  -4.31858636e-02 -1.89984813e-02 -2.91661546e-02  5.77488132e-02\n",
            "   2.41820812e-02 -1.16902711e-02 -6.21435307e-02  2.84351278e-02\n",
            "  -2.37497487e-04 -2.51783282e-02  4.39639203e-03  8.12840238e-02\n",
            "   3.64184231e-02 -6.04005717e-02 -3.65517624e-02 -7.93748796e-02\n",
            "  -5.08528762e-03  6.69699162e-02 -1.17784359e-01  3.23744491e-02\n",
            "  -4.71252874e-02 -1.34460023e-02 -9.48444903e-02  8.24945606e-03\n",
            "  -1.06748864e-02 -6.81882054e-02  1.11822155e-03  2.48020664e-02\n",
            "  -6.35889024e-02  2.84493174e-02 -2.61302870e-02  8.58111531e-02\n",
            "   1.14682272e-01 -5.35345674e-02 -5.63588776e-02  4.26008627e-02\n",
            "   1.09453900e-02  2.09578462e-02  1.00131169e-01  3.26051228e-02\n",
            "  -1.84208736e-01 -3.93208377e-02 -6.91454932e-02 -6.38105273e-02\n",
            "  -6.56385794e-02 -6.41248655e-03 -4.79612686e-02 -7.68132880e-02\n",
            "   2.95384284e-02 -2.29949411e-02  4.17037010e-02 -2.50047632e-02\n",
            "  -4.54508839e-03 -4.17136513e-02 -1.32289762e-02 -6.38357848e-02\n",
            "  -2.46475521e-03 -1.37338284e-02  1.68976765e-02 -6.30398393e-02\n",
            "   8.98880884e-02  4.18170504e-02 -1.85687561e-02 -1.80442186e-08\n",
            "  -1.67998113e-02 -3.21577750e-02  6.30383641e-02 -4.13092263e-02\n",
            "   4.44819145e-02  2.02472718e-03  6.29593357e-02 -5.17368177e-03\n",
            "  -1.00444751e-02 -3.05640567e-02  3.52672040e-02  5.58581203e-02\n",
            "  -4.67125252e-02  3.45102586e-02  3.29578891e-02  4.30114344e-02\n",
            "   2.94362046e-02 -3.03164739e-02 -1.71107911e-02  7.37484396e-02\n",
            "  -5.47910407e-02  2.77515501e-02  6.20159740e-03  1.58800296e-02\n",
            "   3.42978984e-02 -5.15753357e-03  2.35080235e-02  7.53134415e-02\n",
            "   1.92843545e-02  3.36197540e-02  5.09103797e-02  1.52497098e-01\n",
            "   1.64208114e-02  2.70528775e-02  3.75162661e-02  2.18553804e-02\n",
            "   5.66333942e-02 -3.95747684e-02  7.12313056e-02 -5.41377477e-02\n",
            "   1.03770394e-03  2.11853832e-02 -3.56309079e-02  1.09016962e-01\n",
            "   2.76538823e-03  3.13997380e-02  1.38422404e-03 -3.45738344e-02\n",
            "  -4.59277704e-02  2.88083814e-02  7.16906367e-03  4.84685041e-02\n",
            "   2.61018537e-02 -9.44074243e-03  2.82169245e-02  3.48724574e-02\n",
            "   3.69099639e-02 -8.58947542e-03 -3.53205316e-02 -2.47856639e-02\n",
            "  -1.91921201e-02  3.80708352e-02  5.99653907e-02 -4.22287397e-02]\n",
            " [ 8.64386186e-02  1.02762692e-01  5.39453421e-03  2.04442907e-03\n",
            "  -9.96337179e-03  2.53855530e-02  4.92875353e-02 -3.06265932e-02\n",
            "   6.87255114e-02  1.01366024e-02  7.75397494e-02 -9.00807977e-02\n",
            "   6.10618852e-03 -5.69898449e-02  1.41715184e-02  2.80491840e-02\n",
            "  -8.68464410e-02  7.64399469e-02 -1.03491269e-01 -6.77438304e-02\n",
            "   6.99946880e-02  8.44250992e-02 -7.24914437e-03  1.04770698e-02\n",
            "   1.34020578e-02  6.77576959e-02 -9.42086875e-02 -3.71689759e-02\n",
            "   5.22617251e-02 -3.10853552e-02 -9.63406265e-02  1.57716684e-02\n",
            "   2.57866755e-02  7.85245001e-02  7.89949223e-02  1.91516150e-02\n",
            "   1.64356027e-02  3.10080242e-03  3.81311364e-02  2.37090718e-02\n",
            "   1.05389496e-02 -4.40644808e-02  4.41739149e-02 -2.58727819e-02\n",
            "   6.15378395e-02 -4.05427217e-02 -8.64140093e-02  3.19722258e-02\n",
            "  -8.90599797e-04 -2.44436599e-02 -9.19721350e-02  2.33939737e-02\n",
            "  -8.30292925e-02  4.41511124e-02 -2.49693003e-02  6.23020120e-02\n",
            "  -1.30351842e-03  7.51395226e-02  2.46384777e-02 -6.47244602e-02\n",
            "  -1.17727794e-01  3.83392461e-02 -9.11767110e-02  6.35446012e-02\n",
            "   7.62739107e-02 -8.80240798e-02  9.54558328e-03 -4.69718017e-02\n",
            "  -8.41740146e-02  3.88823897e-02 -1.14393570e-01  6.28860481e-03\n",
            "  -3.49362046e-02  2.39751209e-02 -3.31317820e-02 -1.57243311e-02\n",
            "  -3.78955975e-02 -8.81246664e-03  7.06119463e-02  3.28066312e-02\n",
            "   2.03671656e-03 -1.12279005e-01  6.79724757e-03  1.22765619e-02\n",
            "   3.35303470e-02 -1.36201028e-02 -2.25490239e-02 -2.25228630e-02\n",
            "  -2.03194749e-02  5.04297279e-02 -7.48652667e-02 -8.22821334e-02\n",
            "   7.65962452e-02  4.93392572e-02 -3.75553109e-02  1.44635104e-02\n",
            "  -5.72457314e-02 -1.79954097e-02  1.09697975e-01  1.19462803e-01\n",
            "   8.09245277e-04  6.17057607e-02  3.26322243e-02 -1.30780146e-01\n",
            "  -1.48636669e-01 -6.16232641e-02  4.33886163e-02  2.67129503e-02\n",
            "   1.39785577e-02 -3.94002125e-02 -2.52711121e-02  3.87745304e-03\n",
            "   3.58664654e-02 -6.15420863e-02  3.76660600e-02  2.67564878e-02\n",
            "  -3.82659100e-02 -3.54793407e-02 -2.39227656e-02  8.67977142e-02\n",
            "  -1.84063166e-02  7.71038681e-02  1.39856699e-03  7.00383708e-02\n",
            "  -4.77877781e-02 -7.89819881e-02  5.10814637e-02 -2.99868205e-33\n",
            "  -3.91646028e-02 -2.56207213e-03  1.65210441e-02  9.48937424e-03\n",
            "  -5.66219501e-02  6.57783747e-02 -4.77002710e-02  1.11661935e-02\n",
            "  -5.73558100e-02 -9.16253496e-03 -2.17521153e-02 -5.59532531e-02\n",
            "  -1.11422576e-02  9.32792798e-02  1.66765023e-02 -1.36724235e-02\n",
            "   4.34389040e-02  1.87237456e-03  7.29946978e-03  5.16332537e-02\n",
            "   4.80608642e-02  1.35341480e-01 -1.71738882e-02 -1.29698385e-02\n",
            "  -7.50109404e-02  2.61108130e-02  2.69801710e-02  7.83014519e-04\n",
            "  -4.87270020e-02  1.17842406e-02 -4.59580496e-02 -4.83214296e-02\n",
            "  -1.95672009e-02  1.93889365e-02  1.98807381e-02  1.67431980e-02\n",
            "   9.87801179e-02 -2.74087396e-02  2.34808065e-02  3.70229711e-03\n",
            "  -6.14514649e-02 -1.21231726e-03 -9.50469822e-03  9.25156754e-03\n",
            "   2.38443650e-02  8.61232281e-02  2.26790234e-02  5.45120623e-04\n",
            "   3.47129516e-02  6.25461061e-03 -6.92774262e-03  3.92400064e-02\n",
            "   1.15674585e-02  3.26280147e-02  6.22155853e-02  2.76114289e-02\n",
            "   1.86883826e-02  3.55805345e-02  4.11795415e-02  1.54782142e-02\n",
            "   4.22692187e-02  3.82248238e-02  1.00314012e-02 -2.83245761e-02\n",
            "   4.47052233e-02 -4.10459079e-02 -4.50546248e-03 -5.44734262e-02\n",
            "   2.62320898e-02  1.79862268e-02 -1.23118751e-01 -4.66952436e-02\n",
            "  -1.35913501e-02  6.46710545e-02  3.57344374e-03 -1.22234141e-02\n",
            "  -1.79382171e-02 -2.55502760e-02  2.37224102e-02  4.08666953e-03\n",
            "  -6.51475340e-02  4.43651937e-02  4.68595922e-02 -3.25174965e-02\n",
            "   4.02275147e-03 -3.97606660e-03  1.11939432e-02 -9.95597616e-02\n",
            "   3.33168022e-02  8.01060274e-02  9.42692310e-02 -6.38294369e-02\n",
            "   3.23152468e-02 -5.13553470e-02 -7.49873929e-03  5.30053362e-34\n",
            "  -4.13194448e-02  9.49647203e-02 -1.06401451e-01  4.96590361e-02\n",
            "  -3.41913663e-02 -3.16745602e-02 -1.71555988e-02  1.70099782e-03\n",
            "   5.79757616e-02 -1.21778343e-03 -1.68536101e-02 -5.16912825e-02\n",
            "   5.52999079e-02 -3.42647023e-02  3.08179110e-02 -3.10480818e-02\n",
            "   9.27532911e-02  3.72663438e-02 -2.37397570e-02  4.45893593e-02\n",
            "   1.46153392e-02  1.16239391e-01 -5.00112362e-02  3.88716757e-02\n",
            "   4.24751639e-03  2.56975982e-02  3.27243805e-02  4.29906845e-02\n",
            "  -1.36144441e-02  2.56122462e-02  1.06262304e-02 -8.46864507e-02\n",
            "  -9.52982008e-02  1.08400024e-01 -7.51600042e-02 -1.37774404e-02\n",
            "   6.37337863e-02 -4.49666800e-03 -3.25321630e-02  6.23613745e-02\n",
            "   3.48052718e-02 -3.54922079e-02 -2.00222898e-02  3.66607904e-02\n",
            "  -2.48836689e-02  1.01818806e-02 -7.01233447e-02 -4.31950912e-02\n",
            "   2.95332391e-02 -2.94901140e-04 -3.45386341e-02  1.46676125e-02\n",
            "  -9.83970463e-02 -4.70487885e-02 -8.85490514e-03 -8.89914259e-02\n",
            "   3.50995921e-02 -1.29601985e-01 -4.98865247e-02 -6.12047650e-02\n",
            "  -5.97797595e-02  9.46323201e-03  4.91217710e-02 -7.75026828e-02\n",
            "   8.09727237e-02 -4.79257554e-02  2.34377198e-03  7.57031068e-02\n",
            "  -2.40176041e-02 -1.52546111e-02  4.86738496e-02 -3.85968834e-02\n",
            "  -7.04831779e-02 -1.20347980e-02 -3.88790220e-02 -7.76016712e-02\n",
            "  -1.07243471e-02  1.04188547e-02 -2.13753786e-02 -9.17386264e-02\n",
            "  -1.11344634e-02 -2.96065565e-02  2.46458296e-02  4.65711206e-03\n",
            "  -1.63449869e-02 -3.95219885e-02  7.73373544e-02 -2.84732413e-02\n",
            "  -3.69940535e-03  8.27664956e-02 -1.10408571e-02  3.13983783e-02\n",
            "   5.35094850e-02  5.75145967e-02 -3.17622013e-02 -1.52911266e-08\n",
            "  -7.99661577e-02 -4.76796888e-02 -8.59789103e-02  5.69616407e-02\n",
            "  -4.08866331e-02  2.23832335e-02 -4.64444654e-03 -3.80131118e-02\n",
            "  -3.10670976e-02 -1.07278181e-02  1.97698642e-02  7.76997907e-03\n",
            "  -6.09474909e-03 -3.86376455e-02  2.80271936e-02  6.78137466e-02\n",
            "  -2.35351119e-02  3.21747400e-02  8.02540779e-03 -2.39106789e-02\n",
            "  -1.21997879e-03  3.14598978e-02 -5.24925627e-02 -8.06809310e-03\n",
            "   3.14774481e-03  5.11496589e-02 -4.44104858e-02  6.36013299e-02\n",
            "   3.85083668e-02  3.30432989e-02 -4.18728497e-03  4.95592505e-02\n",
            "  -5.69604859e-02 -6.49709674e-03 -2.49793380e-02 -1.60867255e-02\n",
            "   6.62289262e-02 -2.06310432e-02  1.08045794e-01  1.68547090e-02\n",
            "   1.43812457e-02 -1.32127134e-02 -1.29387408e-01  6.95215985e-02\n",
            "  -5.55773489e-02 -6.75413534e-02 -5.45820314e-03 -6.13593776e-03\n",
            "   3.90840992e-02 -6.28779531e-02  3.74063291e-02 -1.16570722e-02\n",
            "   1.29149891e-02 -5.52496240e-02  5.16076311e-02 -4.30842303e-03\n",
            "   5.80247678e-02  1.86945442e-02  2.27810629e-02  3.21666077e-02\n",
            "   5.37978895e-02  7.02849105e-02  7.49311745e-02 -8.41775537e-02]]\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The project aims to train sentence embedding models on very large sentence level datasets using a self-supervised contrastive learning objective. We used the pretrained **nreimers/MiniLM-L6-H384-uncased** model and fine-tuned in on a 1B sentence pairs dataset. We use a contrastive learning objective: given a sentence from the pair, the model should predict which out of a set of randomly sampled other sentences, was actually paired with it in our dataset.\n",
        "\n",
        "This is a 6 layer version of **microsoft/MiniLM-L12-H384-uncased** by keeping only every second layer.\n",
        "\n",
        "**MiniLM**: Small and Fast Pre-trained Models for Language Understanding and Generation\n",
        "\n",
        "MiniLM is a distilled model from the paper \"MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers\".\n",
        "Please find the information about preprocessing, training and full details of the MiniLM in the original MiniLM repository.\n",
        "Please note: This checkpoint can be an inplace substitution for BERT and it needs to be fine-tuned before use!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------+------------+\n",
            "|                            Modules                             | Parameters |\n",
            "+----------------------------------------------------------------+------------+\n",
            "|         0.auto_model.embeddings.word_embeddings.weight         |  11720448  |\n",
            "|       0.auto_model.embeddings.position_embeddings.weight       |   196608   |\n",
            "|      0.auto_model.embeddings.token_type_embeddings.weight      |    768     |\n",
            "|            0.auto_model.embeddings.LayerNorm.weight            |    384     |\n",
            "|             0.auto_model.embeddings.LayerNorm.bias             |    384     |\n",
            "|    0.auto_model.encoder.layer.0.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.0.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.0.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.0.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.0.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.0.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.0.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.0.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.0.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.0.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.0.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.0.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.0.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.0.output.LayerNorm.bias       |    384     |\n",
            "|    0.auto_model.encoder.layer.1.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.1.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.1.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.1.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.1.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.1.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.1.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.1.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.1.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.1.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.1.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.1.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.1.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.1.output.LayerNorm.bias       |    384     |\n",
            "|    0.auto_model.encoder.layer.2.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.2.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.2.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.2.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.2.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.2.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.2.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.2.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.2.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.2.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.2.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.2.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.2.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.2.output.LayerNorm.bias       |    384     |\n",
            "|    0.auto_model.encoder.layer.3.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.3.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.3.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.3.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.3.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.3.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.3.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.3.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.3.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.3.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.3.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.3.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.3.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.3.output.LayerNorm.bias       |    384     |\n",
            "|    0.auto_model.encoder.layer.4.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.4.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.4.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.4.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.4.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.4.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.4.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.4.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.4.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.4.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.4.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.4.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.4.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.4.output.LayerNorm.bias       |    384     |\n",
            "|    0.auto_model.encoder.layer.5.attention.self.query.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.5.attention.self.query.bias     |    384     |\n",
            "|     0.auto_model.encoder.layer.5.attention.self.key.weight     |   147456   |\n",
            "|      0.auto_model.encoder.layer.5.attention.self.key.bias      |    384     |\n",
            "|    0.auto_model.encoder.layer.5.attention.self.value.weight    |   147456   |\n",
            "|     0.auto_model.encoder.layer.5.attention.self.value.bias     |    384     |\n",
            "|   0.auto_model.encoder.layer.5.attention.output.dense.weight   |   147456   |\n",
            "|    0.auto_model.encoder.layer.5.attention.output.dense.bias    |    384     |\n",
            "| 0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight |    384     |\n",
            "|  0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias  |    384     |\n",
            "|     0.auto_model.encoder.layer.5.intermediate.dense.weight     |   589824   |\n",
            "|      0.auto_model.encoder.layer.5.intermediate.dense.bias      |    1536    |\n",
            "|        0.auto_model.encoder.layer.5.output.dense.weight        |   589824   |\n",
            "|         0.auto_model.encoder.layer.5.output.dense.bias         |    384     |\n",
            "|      0.auto_model.encoder.layer.5.output.LayerNorm.weight      |    384     |\n",
            "|       0.auto_model.encoder.layer.5.output.LayerNorm.bias       |    384     |\n",
            "|                0.auto_model.pooler.dense.weight                |   147456   |\n",
            "|                 0.auto_model.pooler.dense.bias                 |    384     |\n",
            "+----------------------------------------------------------------+------------+\n",
            "Total Trainable Params: 22713216\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "22713216"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading .gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 3.98MB/s]\n",
            "Downloading 1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 698kB/s]\n",
            "Downloading README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 38.8MB/s]\n",
            "Downloading config.json: 100%|██████████| 571/571 [00:00<00:00, 4.64MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 866kB/s]\n",
            "Downloading data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 62.7MB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [01:31<00:00, 4.80MB/s] \n",
            "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 246kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 922kB/s]\n",
            "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.67MB/s]\n",
            "Downloading tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 1.41MB/s]\n",
            "Downloading train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 25.7MB/s]\n",
            "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.96MB/s]\n",
            "Downloading modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.60MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_big = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------+------------+\n",
            "|                         Modules                          | Parameters |\n",
            "+----------------------------------------------------------+------------+\n",
            "|      0.auto_model.embeddings.word_embeddings.weight      |  23444736  |\n",
            "|    0.auto_model.embeddings.position_embeddings.weight    |   394752   |\n",
            "|         0.auto_model.embeddings.LayerNorm.weight         |    768     |\n",
            "|          0.auto_model.embeddings.LayerNorm.bias          |    768     |\n",
            "|   0.auto_model.encoder.layer.0.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.0.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.0.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.0.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.0.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.0.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.0.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.0.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.0.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.0.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.0.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.0.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.0.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.0.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.0.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.0.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.1.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.1.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.1.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.1.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.1.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.1.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.1.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.1.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.1.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.1.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.1.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.1.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.1.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.1.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.1.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.1.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.2.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.2.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.2.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.2.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.2.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.2.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.2.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.2.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.2.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.2.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.2.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.2.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.2.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.2.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.2.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.2.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.3.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.3.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.3.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.3.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.3.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.3.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.3.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.3.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.3.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.3.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.3.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.3.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.3.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.3.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.3.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.3.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.4.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.4.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.4.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.4.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.4.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.4.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.4.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.4.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.4.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.4.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.4.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.4.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.4.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.4.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.4.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.4.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.5.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.5.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.5.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.5.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.5.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.5.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.5.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.5.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.5.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.5.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.5.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.5.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.5.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.5.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.5.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.5.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.6.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.6.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.6.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.6.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.6.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.6.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.6.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.6.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.6.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.6.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.6.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.6.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.6.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.6.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.6.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.6.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.7.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.7.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.7.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.7.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.7.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.7.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.7.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.7.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.7.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.7.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.7.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.7.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.7.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.7.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.7.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.7.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.8.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.8.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.8.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.8.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.8.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.8.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.8.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.8.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.8.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.8.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.8.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.8.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.8.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.8.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.8.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.8.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.9.attention.attn.q.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.9.attention.attn.q.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.9.attention.attn.k.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.9.attention.attn.k.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.9.attention.attn.v.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.9.attention.attn.v.bias    |    768     |\n",
            "|   0.auto_model.encoder.layer.9.attention.attn.o.weight   |   589824   |\n",
            "|    0.auto_model.encoder.layer.9.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.9.attention.LayerNorm.weight  |    768     |\n",
            "|  0.auto_model.encoder.layer.9.attention.LayerNorm.bias   |    768     |\n",
            "|  0.auto_model.encoder.layer.9.intermediate.dense.weight  |  2359296   |\n",
            "|   0.auto_model.encoder.layer.9.intermediate.dense.bias   |    3072    |\n",
            "|     0.auto_model.encoder.layer.9.output.dense.weight     |  2359296   |\n",
            "|      0.auto_model.encoder.layer.9.output.dense.bias      |    768     |\n",
            "|   0.auto_model.encoder.layer.9.output.LayerNorm.weight   |    768     |\n",
            "|    0.auto_model.encoder.layer.9.output.LayerNorm.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.10.attention.attn.q.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.10.attention.attn.q.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.10.attention.attn.k.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.10.attention.attn.k.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.10.attention.attn.v.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.10.attention.attn.v.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.10.attention.attn.o.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.10.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.10.attention.LayerNorm.weight |    768     |\n",
            "|  0.auto_model.encoder.layer.10.attention.LayerNorm.bias  |    768     |\n",
            "| 0.auto_model.encoder.layer.10.intermediate.dense.weight  |  2359296   |\n",
            "|  0.auto_model.encoder.layer.10.intermediate.dense.bias   |    3072    |\n",
            "|    0.auto_model.encoder.layer.10.output.dense.weight     |  2359296   |\n",
            "|     0.auto_model.encoder.layer.10.output.dense.bias      |    768     |\n",
            "|  0.auto_model.encoder.layer.10.output.LayerNorm.weight   |    768     |\n",
            "|   0.auto_model.encoder.layer.10.output.LayerNorm.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.11.attention.attn.q.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.11.attention.attn.q.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.11.attention.attn.k.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.11.attention.attn.k.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.11.attention.attn.v.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.11.attention.attn.v.bias    |    768     |\n",
            "|  0.auto_model.encoder.layer.11.attention.attn.o.weight   |   589824   |\n",
            "|   0.auto_model.encoder.layer.11.attention.attn.o.bias    |    768     |\n",
            "| 0.auto_model.encoder.layer.11.attention.LayerNorm.weight |    768     |\n",
            "|  0.auto_model.encoder.layer.11.attention.LayerNorm.bias  |    768     |\n",
            "| 0.auto_model.encoder.layer.11.intermediate.dense.weight  |  2359296   |\n",
            "|  0.auto_model.encoder.layer.11.intermediate.dense.bias   |    3072    |\n",
            "|    0.auto_model.encoder.layer.11.output.dense.weight     |  2359296   |\n",
            "|     0.auto_model.encoder.layer.11.output.dense.bias      |    768     |\n",
            "|  0.auto_model.encoder.layer.11.output.LayerNorm.weight   |    768     |\n",
            "|   0.auto_model.encoder.layer.11.output.LayerNorm.bias    |    768     |\n",
            "|   0.auto_model.encoder.relative_attention_bias.weight    |    384     |\n",
            "|             0.auto_model.pooler.dense.weight             |   589824   |\n",
            "|              0.auto_model.pooler.dense.bias              |    768     |\n",
            "+----------------------------------------------------------+------------+\n",
            "Total Trainable Params: 109486464\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "109486464"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_parameters(model_big)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
